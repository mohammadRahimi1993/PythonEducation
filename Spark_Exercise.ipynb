{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1C6OSua500dnRzKb5_T_RfXxsLaOENi1g",
      "authorship_tag": "ABX9TyMw87jz04+4/jIblSppsHYC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadRahimi1993/PythonEducation/blob/main/Spark_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz1VhRtICBC_",
        "outputId": "921cd771-e746-4527-8198-df6072ea14eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# innstall java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# set your spark folder to your system path environment. \n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "IIUdmIq2DG38"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "3RjsPsGuG4v3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"PySpark 3.2 on Google Cloab\").getOrCreate()"
      ],
      "metadata": {
        "id": "SzSAwIoYTS5T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ArrayType\n",
        "from pyspark.sql.functions import col,array_contains\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "\n",
        "arrayStructureData = [(\"Hossein\",\"M\"),(\"Hassan\",\"M\"),(\"Ali\",\"M\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),\n",
        "(\"Abbas\",\"M\"),(\"zahra\",\"F\"),(\"bahar\",\"F\"),(\"sahar\",\"F\"),(\"zeinab\",\"F\"),(\"sahab\",\"M\"),\n",
        "(\"alireza\",\"M\"),(\"sadegh\",\"M\"),(\"sajad\",\"M\"),(\"farshad\",\"M\"),(\"mohsen\",\"M\"),(\"mahdi\",\"M\"),\n",
        "(\"milad\",\"M\"),(\"aliye\",\"M\"),(\"amirali\",\"M\"),(\"farzin\",\"M\"),(\"mokhtar\",\"M\"),(\"rashid\",\"M\"),\n",
        "(\"raziye\",\"F\"),(\"marziye\",\"F\"),(\"saed\",\"M\"),(\"esi\",\"M\"),(\"amir\",\"M\"),(\"hossein\",\"M\"),\n",
        "(\"sharbano\",\"M\"),(\"Mohammad\",\"M\"),(\"Hassan\",\"F\"),(\"Ali\",\"F\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),(\"Abbas\",\"M\"),        \n",
        "(\"heidar\",\"M\"),(\"ghohar\",\"F\"),(\"setayesh\",\"F\"),(\"masoud\",\"M\"),(\"elham\",\"M\"),(\"Abbas\",\"M\"),      \n",
        "(\"Mohammad\",\"M\"),(\"Hassan\",\"F\"),(\"Ali\",\"F\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),(\"Abbas\",\"M\"),       \n",
        "(\"Mohammad\",\"M\"),(\"Hassan\",\"F\"),(\"Ali\",\"F\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),(\"Abbas\",\"M\"),\n",
        "(\"Mohammad\",\"M\"),(\"Hassan\",\"F\"),(\"Ali\",\"F\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),(\"Abbas\",\"M\"),(\"Mohammad\",\"M\"),\n",
        "(\"Hassan\",\"F\"),(\"Ali\",\"F\"),(\"Hossein\",\"M\"),(\"Sajad\",\"M\"),(\"Abbas\",\"M\")]\n",
        "        \n",
        "arrayStructureSchema = StructType([\n",
        "         StructField('Name', StringType(), True),\n",
        "         StructField('gender', StringType(), True)\n",
        "         ])\n",
        "\n",
        "\n",
        "df = spark.createDataFrame(data = arrayStructureData, schema = arrayStructureSchema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n",
        "df.filter(df.Name == \"amirali\").show(truncate=False) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxGd1egjHObh",
        "outputId": "ea3bb09d-6364-48a7-a99e-b4c8713f1ad2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+-------+------+\n",
            "|Name   |gender|\n",
            "+-------+------+\n",
            "|Hossein|M     |\n",
            "|Hassan |M     |\n",
            "|Ali    |M     |\n",
            "|Hossein|M     |\n",
            "|Sajad  |M     |\n",
            "|Abbas  |M     |\n",
            "|zahra  |F     |\n",
            "|bahar  |F     |\n",
            "|sahar  |F     |\n",
            "|zeinab |F     |\n",
            "|sahab  |M     |\n",
            "|alireza|M     |\n",
            "|sadegh |M     |\n",
            "|sajad  |M     |\n",
            "|farshad|M     |\n",
            "|mohsen |M     |\n",
            "|mahdi  |M     |\n",
            "|milad  |M     |\n",
            "|aliye  |M     |\n",
            "|amirali|M     |\n",
            "+-------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------+------+\n",
            "|Name   |gender|\n",
            "+-------+------+\n",
            "|amirali|M     |\n",
            "+-------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\").getOrCreate()\n",
        "\n",
        "data = [\"Mohammad\",\"masoud\",\"raziye\",\"maziye\",\n",
        "\"saeid\",\"sajad\",\"ali\",\"hossein\",\"hassan\", \"hame\",\"hamid\",\"omid\",\"Mohammadreza\", \"farzaneh\",\"ahmad\",\"ghasem\",\"sahar\",\n",
        "\"setayesh\", \"vahid\",\"mahid\",\"esmael\",\"jan\",\"habib\",\"soheil\",\"Hossein\",\"Hassan\",\"Ali\", \"Hossein\",\"Sajad\", \"Abbas\",\"zahra\",\"bahar\", \"sahar\",\"zeinab\",\n",
        "\"sahab\",\"alireza\",\"sadegh\",\"sajad\",\"farshad\",\"mohsen\",\"mahdi\",\"milad\",\"aliye\",\"amirali\",\"farzin\"\n",
        "\"mokhtar\",\"rashid\",\"raziye\",\"marziye\",\"saed\",\"esi\",\"amir\",\n",
        "\"hossein\",\"sharbano\",\"Mohammad\",\"Hassan\",\"Ali\",\"Hossein\",\"Sajad\",\"Abbas\",\"heidar\",\"ghohar\",\"setayesh\",\"masoud\",\"elham\",\"Abbas\",      \n",
        "\"Mohammad\",\"Hassan\",\"Ali\",\"Hossein\",\"Sajad\",\"Abbas\",\"Mohammad\",\"Hassan\",\"Ali\",\"Hossein\",\"Sajad\",\"M\",\"Abbas\",\n",
        "\"Mohammad\",\"Hassan\",\"Ali\",\"Hossein\",\"Sajad\",\"Abbas\",\"Mohammad\",\"Hassan\",\"Ali\",\"Hossein\",\"Sajad\",\"Abbas\"]\n",
        "\n",
        "rdd=spark.sparkContext.parallelize(data)\n",
        "rdd2=rdd.map(lambda x: (x.upper()))\n",
        "for element in rdd2.collect():\n",
        "    print(element)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kScFyBLHOmH",
        "outputId": "b4f396f8-8b4c-4457-f24c-5a3132e35ae2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MOHAMMAD\n",
            "MASOUD\n",
            "RAZIYE\n",
            "MAZIYE\n",
            "SAEID\n",
            "SAJAD\n",
            "ALI\n",
            "HOSSEIN\n",
            "HASSAN\n",
            "HAME\n",
            "HAMID\n",
            "OMID\n",
            "MOHAMMADREZA\n",
            "FARZANEH\n",
            "AHMAD\n",
            "GHASEM\n",
            "SAHAR\n",
            "SETAYESH\n",
            "VAHID\n",
            "MAHID\n",
            "ESMAEL\n",
            "JAN\n",
            "HABIB\n",
            "SOHEIL\n",
            "HOSSEIN\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "ABBAS\n",
            "ZAHRA\n",
            "BAHAR\n",
            "SAHAR\n",
            "ZEINAB\n",
            "SAHAB\n",
            "ALIREZA\n",
            "SADEGH\n",
            "SAJAD\n",
            "FARSHAD\n",
            "MOHSEN\n",
            "MAHDI\n",
            "MILAD\n",
            "ALIYE\n",
            "AMIRALI\n",
            "FARZINMOKHTAR\n",
            "RASHID\n",
            "RAZIYE\n",
            "MARZIYE\n",
            "SAED\n",
            "ESI\n",
            "AMIR\n",
            "HOSSEIN\n",
            "SHARBANO\n",
            "MOHAMMAD\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "ABBAS\n",
            "HEIDAR\n",
            "GHOHAR\n",
            "SETAYESH\n",
            "MASOUD\n",
            "ELHAM\n",
            "ABBAS\n",
            "MOHAMMAD\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "ABBAS\n",
            "MOHAMMAD\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "M\n",
            "ABBAS\n",
            "MOHAMMAD\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "ABBAS\n",
            "MOHAMMAD\n",
            "HASSAN\n",
            "ALI\n",
            "HOSSEIN\n",
            "SAJAD\n",
            "ABBAS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import add\n",
        "df1 = spark.read.text(\"/content/drive/MyDrive/Text.txt\",lineSep=\" \").rdd\n",
        "rrmap=df1.map(lambda x: list(x))\n",
        "for element in rrmap.collect():\n",
        "    print(element[0].upper())\n",
        "df1.reduce(add)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLLeDjyAHOpy",
        "outputId": "9bd0a14d-a942-4f63-8455-2a09a71d3532"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WESTERN\n",
            "NATIONS\n",
            "AGREED\n",
            "TO\n",
            "EXCLUDE\n",
            "SOME\r\n",
            "RUSSIAN\n",
            "BANKS\n",
            "FROM\n",
            "THE\n",
            "SWIFT\n",
            "MESSAGING\n",
            "SYSTEM\r\n",
            "USED\n",
            "FOR\n",
            "TRILLIONS\n",
            "OF\n",
            "DOLLARS\n",
            "WORTH\n",
            "OF\n",
            "TRANSACTIONS\r\n",
            "BETWEEN\n",
            "BANKS\n",
            "AROUND\n",
            "THE\n",
            "WORLD\n",
            "FURTHER\r\n",
            "ISOLATING\n",
            "\r\n",
            "RUSSIA’S\n",
            "\r\n",
            "ECONOMY\n",
            "AND\n",
            "FINANCIAL\n",
            "SYSTEM\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Western',\n",
              " 'nations',\n",
              " 'agreed',\n",
              " 'to',\n",
              " 'exclude',\n",
              " 'some\\r\\nRussian',\n",
              " 'banks',\n",
              " 'from',\n",
              " 'the',\n",
              " 'SWIFT',\n",
              " 'messaging',\n",
              " 'system\\r\\nused',\n",
              " 'for',\n",
              " 'trillions',\n",
              " 'of',\n",
              " 'dollars',\n",
              " 'worth',\n",
              " 'of',\n",
              " 'transactions\\r\\nbetween',\n",
              " 'banks',\n",
              " 'around',\n",
              " 'the',\n",
              " 'world',\n",
              " 'further\\r\\nisolating',\n",
              " '\\r\\nRussia’s',\n",
              " '\\r\\neconomy',\n",
              " 'and',\n",
              " 'financial',\n",
              " 'system')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName(\"parquetFile\").getOrCreate()\n",
        "data =[(\"James \",\"\",\"Smith\",\"36636\",\"M\",3000),\n",
        "              (\"Michael \",\"Rose\",\"\",\"40288\",\"M\",4000),\n",
        "              (\"Robert \",\"\",\"Williams\",\"42114\",\"M\",4000),\n",
        "              (\"Maria \",\"Anne\",\"Jones\",\"39192\",\"F\",4000),\n",
        "              (\"Jen\",\"Mary\",\"Brown\",\"\",\"F\",-1)]\n",
        "columns=[\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df=spark.createDataFrame(data,columns)\n",
        "df.write.mode(\"overwrite\").parquet(\"/tmp/output/people.parquet\")\n",
        "parDF1=spark.read.parquet(\"/tmp/output/people.parquet\")\n",
        "parDF1.createOrReplaceTempView(\"parquetTable\")\n",
        "parDF1.printSchema()\n",
        "parDF1.show(truncate=False)\n",
        "\n",
        "parkSQL = spark.sql(\"select * from ParquetTable where salary >= 4000 \")\n",
        "parkSQL.show(truncate=False)\n",
        "\n",
        "spark.sql(\"CREATE TEMPORARY VIEW PERSON USING parquet OPTIONS (path \\\"/tmp/output/people.parquet\\\")\")\n",
        "spark.sql(\"SELECT * FROM PERSON\").show()\n",
        "\n",
        "df.write.partitionBy(\"gender\",\"salary\").mode(\"overwrite\").parquet(\"/tmp/output/people2.parquet\")\n",
        "\n",
        "parDF2=spark.read.parquet(\"/tmp/output/people2.parquet/gender=M\")\n",
        "parDF2.show(truncate=False)\n",
        "\n",
        "spark.sql(\"CREATE TEMPORARY VIEW PERSON2 USING parquet OPTIONS (path \\\"/tmp/output/people2.parquet/gender=F\\\")\")\n",
        "spark.sql(\"SELECT * FROM PERSON2\" ).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OYGg8L9O7Yb",
        "outputId": "e05796a1-c851-4de4-e24d-16c4e8c60f7e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- firstname: string (nullable = true)\n",
            " |-- middlename: string (nullable = true)\n",
            " |-- lastname: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- salary: long (nullable = true)\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|dob  |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Jen      |Mary      |Brown   |     |F     |-1    |\n",
            "|James    |          |Smith   |36636|M     |3000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|dob  |gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|Robert   |          |Williams|42114|M     |4000  |\n",
            "|Maria    |Anne      |Jones   |39192|F     |4000  |\n",
            "|Michael  |Rose      |        |40288|M     |4000  |\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|firstname|middlename|lastname|  dob|gender|salary|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "|  Robert |          |Williams|42114|     M|  4000|\n",
            "|   Maria |      Anne|   Jones|39192|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|     |     F|    -1|\n",
            "|   James |          |   Smith|36636|     M|  3000|\n",
            "| Michael |      Rose|        |40288|     M|  4000|\n",
            "+---------+----------+--------+-----+------+------+\n",
            "\n",
            "+---------+----------+--------+-----+------+\n",
            "|firstname|middlename|lastname|dob  |salary|\n",
            "+---------+----------+--------+-----+------+\n",
            "|Robert   |          |Williams|42114|4000  |\n",
            "|Michael  |Rose      |        |40288|4000  |\n",
            "|James    |          |Smith   |36636|3000  |\n",
            "+---------+----------+--------+-----+------+\n",
            "\n",
            "+---------+----------+--------+-----+------+\n",
            "|firstname|middlename|lastname|  dob|salary|\n",
            "+---------+----------+--------+-----+------+\n",
            "|   Maria |      Anne|   Jones|39192|  4000|\n",
            "|      Jen|      Mary|   Brown|     |    -1|\n",
            "+---------+----------+--------+-----+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}